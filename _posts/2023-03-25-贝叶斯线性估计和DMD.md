---
layout: post
title:  "贝叶斯线性估计和DMD"
author: "Geoffrey Hou"
comments: true
tags: NR
excerpt_separator: <!--more-->
sticky: true
hidden: true
---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

最近在学习统计信号处理的估计理论部分，贝叶斯估计理论在DMD中的应用有些需要记录。<!--more-->

MMSE的一般表达式如下：
<center>$\widehat{\boldsymbol{\theta}}=\mathrm{E}[\boldsymbol{\theta}|\boldsymbol{y}]=\int\boldsymbol{\theta}p(\boldsymbol{\theta}|\boldsymbol{y})\mathrm{d}\boldsymbol{\theta}, p(\boldsymbol{\theta}|\boldsymbol{y})=\frac{p(\boldsymbol{y}|\boldsymbol{\theta})p(\boldsymbol{\theta})}{\int p(\boldsymbol{y}|\boldsymbol{\theta}) p(\boldsymbol{\theta})\mathrm{d}\boldsymbol{\theta}}$</center>
需要求多重积分，如果不做任何假设，很难求出闭合表达式。有两种假设可以考虑：联合高斯和线性估计量。

## 联合高斯假设下的线性贝叶斯估计量
### 多维高斯条件PDF
如果$\boldsymbol{x_{k \times 1}}$和$\boldsymbol{y_{l \times 1}}$是联合高斯的，均值矢量是$\left[E[\boldsymbol{x}]^{\mathrm{T}} \quad E[\boldsymbol{y}]^{\mathrm{T}}\right]^{\mathrm{T}}$，协方差是

$$
 \boldsymbol{R}=\left[
 \begin{matrix}
   \boldsymbol{R_{\boldsymbol{x} \boldsymbol{x}}} & \boldsymbol{R_{\boldsymbol{x} \boldsymbol{y}}} \\
   \boldsymbol{R_{\boldsymbol{y} \boldsymbol{x}}} & \boldsymbol{R_{\boldsymbol{y} \boldsymbol{y}}}
 \end{matrix}
 \right]
$$

那么条件PDF也是高斯的，并且

$$\mathrm{E}[\boldsymbol{y}|\boldsymbol{x}]=\mathrm{E}[\boldsymbol{y}]+\boldsymbol{R_{\boldsymbol{y}\boldsymbol{x}}}\boldsymbol{R_{\boldsymbol{x}\boldsymbol{x}}}^{-1}(\boldsymbol{x}-\mathrm{E}[\boldsymbol{x}])$$

$$\boldsymbol{R_{\boldsymbol{y}|\boldsymbol{x}}}=\boldsymbol{R_{\boldsymbol{y}\boldsymbol{y}}}-\boldsymbol{R_{\boldsymbol{y}\boldsymbol{x}}}\boldsymbol{R_{\boldsymbol{x}\boldsymbol{x}}}^{-1}\boldsymbol{R_{\boldsymbol{x}\boldsymbol{y}}}$$

### 贝叶斯一般线性模型
数据模型满足
<center>$\boldsymbol{y}=\boldsymbol{H\theta+n}$</center>
其中$\boldsymbol{y}$是$N \times 1$的观测数据矢量，$\boldsymbol{H}$是已知$N \times p$矩阵，$\boldsymbol{\theta}$是$p \times 1$的随机矢量，先验概率PDF满足均值为$\boldsymbol{\mu_{\theta}} $ ，方差为$\boldsymbol{C_{\theta}}$的高斯分布，$\boldsymbol{n}$是$N \times 1$的噪声矢量，PDF满足均值为$\boldsymbol{0}$，方差为$\boldsymbol{C_\theta}$的高斯分布，并且和$\boldsymbol{\theta}$无关。
在$\boldsymbol{y}$和$\boldsymbol{\theta}$联合高斯的条件下，后验PDF也是高斯的。

把$\boldsymbol{H\theta+n}$看作上小节中的$\boldsymbol{x}$，把$\boldsymbol{\theta}$看作上小节中的$\boldsymbol{y}$，有下面的推导：
<center>$$\mathrm{E}[\boldsymbol{x}]=\mathrm{E}[\boldsymbol{H} \boldsymbol{\theta}+\boldsymbol{n}]=\boldsymbol{H}\mathrm{E}[\boldsymbol{\theta}]=\boldsymbol{H}\boldsymbol{\mu}_\theta$$</center>
<center>$$\mathrm{E}[\boldsymbol{y}]=\mathrm{E}[\boldsymbol{\theta}]=\boldsymbol{\mu}_\theta$$</center>
<center>$$\begin{aligned} \boldsymbol{R}_{\boldsymbol{x} \boldsymbol{x}} & =\mathrm{E}\left[(\boldsymbol{x}-\mathrm{E}[\boldsymbol{x}])(\boldsymbol{x}-\mathrm{E}[\boldsymbol{x}])^{\mathrm{T}}\right] \\ & =\mathrm{E}\left[\left(\boldsymbol{H} \boldsymbol{\theta}+\boldsymbol{n}-\boldsymbol{H} \boldsymbol{\mu}_{\boldsymbol{\theta}}\right)\left(\boldsymbol{H} \boldsymbol{\theta}+\boldsymbol{n}-\boldsymbol{H} \boldsymbol{\mu}_{\boldsymbol{\theta}}\right)^{\mathrm{T}}\right] \\ & =\mathrm{E}\left[\left(\boldsymbol{H}\left(\boldsymbol{\theta}-\boldsymbol{\mu}_{\boldsymbol{\theta}}\right)+\boldsymbol{n}\right)\left(\boldsymbol{H}\left(\boldsymbol{\theta}-\boldsymbol{\mu}_{\boldsymbol{\theta}}\right)+\boldsymbol{n}\right)^{\mathrm{T}}\right] \\ & =\boldsymbol{H}\mathrm{E}\left[\left(\boldsymbol{\theta}-\boldsymbol{\mu}_{\boldsymbol{\theta}}\right)\left(\boldsymbol{\theta}-\boldsymbol{\mu}_{\boldsymbol{\theta}}\right)^{\mathrm{T}}\right] \boldsymbol{H}^{\mathrm{T}}+\mathrm{E}\left[\boldsymbol{n} \boldsymbol{n}^{\mathrm{T}}\right] \\ & =\boldsymbol{H} \boldsymbol{C}_{\boldsymbol{\theta}} \boldsymbol{H}^{\mathrm{T}}+\boldsymbol{C}_{\boldsymbol{n}}\end{aligned}$$</center>
<center>$$
\begin{aligned}
\boldsymbol{R}_{\boldsymbol{y} \boldsymbol{x}} & =\mathrm{E}\left[(\boldsymbol{y}-\mathrm{E}[\boldsymbol{y}])(\boldsymbol{x}-\mathrm{E}[\boldsymbol{x}])^{\mathrm{T}}\right] \\
& =\mathrm{E}\left[\left(\boldsymbol{\theta}-\boldsymbol{\mu}_{\boldsymbol{\theta}}\right)\left(\boldsymbol{H}\left(\boldsymbol{\theta}-\boldsymbol{\mu}_{\boldsymbol{\theta}}\right)+\boldsymbol{n}\right)^{\mathrm{T}}\right] \\
& =\boldsymbol{C}_{\boldsymbol{\theta}} \boldsymbol{H}^{\mathrm{T}}
\end{aligned}
$$</center>
<center>$$
\boldsymbol{R_{\boldsymbol{x}\boldsymbol{y}}}=\boldsymbol{H}\boldsymbol{C_\theta}
$$</center>
<center>$$
\mathrm{E}[\boldsymbol{\theta} \mid \boldsymbol{y}]=\boldsymbol{\mu}_{\boldsymbol{\theta}}+\boldsymbol{C}_{\boldsymbol{\theta}} \boldsymbol{H}^{\mathrm{T}}\left(\boldsymbol{H} \boldsymbol{C}_{\boldsymbol{\theta}} \boldsymbol{H}^{\mathrm{T}}+\boldsymbol{C}_{\boldsymbol{n}}\right)^{-\mathbf{1}}\left(\boldsymbol{y}-\boldsymbol{H} \boldsymbol{\mu}_{\boldsymbol{\theta}}\right)
$$</center>
<center>$$
\boldsymbol{R_{\theta|y}}=\boldsymbol{C_\theta}-\boldsymbol{C_\theta}\boldsymbol{H}^{\mathrm{T}}\left(\boldsymbol{H}\boldsymbol{C_\theta}\boldsymbol{H}^{\mathrm{T}}+\boldsymbol{C_n}\right)^{-1}\boldsymbol{H}\boldsymbol{C_\theta}
$$</center>

## 线性贝叶斯估计量
这里没有做联合高斯假设，只限定估计量是线性的。
### LMMSE
#### 标量参数的LMMSE
用$\left.\boldsymbol{y}=\left[\begin{array}{llll}y[0] & y[1\end{array}\right] \quad \cdots \quad y[N-1]\right]^{\mathrm{T}}$表示观测数据矢量，用$\left.\boldsymbol{a}=\left[\begin{array}{llll}a[0] & a[1\end{array}\right] \quad \cdots \quad a[N-1]\right]^{\mathrm{T}}$表示加权系数矢量，标量$\theta$的线性估计量可以表示为

<center>$$
\hat{\theta}=\sum_{i=0}^{N-1} a[i] y[i]+a[N]
$$</center>

通过调整加权系数使得贝叶斯MSE $\operatorname{mse}(\hat{\theta})=\mathrm{E}\left[(\theta-\hat{\theta})^2\right]$最小，即可得到线性最小均方误差估计。

推导过程如下：
首先，贝叶斯MSE对$a[N]$求导得到：
<center>
$$
\begin{aligned}
\frac{\partial}{\partial a[N]} \mathrm{E}\left[(\theta-\hat{\theta})^2\right] & =\frac{\partial}{\partial a[N]} \mathrm{E}\left[\left(\theta-\sum_{i=0}^{N-1} a[i] y[i]-a[N]\right)^2\right] \\
& =-2 \mathrm{E}\left[\theta-\sum_{i=0}^{N-1} a[i] y[i]-a[N]\right]
\end{aligned}
$$
</center>
令其为零，得到$a[N]=\mathrm{E}[\theta]-\sum_{i=0}^{N-1} a[i] \mathrm{E}[y[i]]$。这样$\operatorname{mse}(\hat{\theta})$可以写成矩阵形式
<center>
$\operatorname{mse}(\hat{\theta})=\boldsymbol{a}^{\mathrm{T}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}} \boldsymbol{a}-\boldsymbol{a}^{\mathrm{T}} \boldsymbol{R}_{\boldsymbol{y} \theta}-\boldsymbol{R}_{\theta \boldsymbol{y}} \boldsymbol{a}+\boldsymbol{R}_{\theta \theta}$
</center>
对$\boldsymbol{a}$求导，
<center>
$$
\frac{\partial \mathrm{mse}(\hat{\theta})}{\partial \boldsymbol{a}}=2 \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}} \boldsymbol{a}-2 \boldsymbol{R}_{\boldsymbol{y} \theta}
，令其为零，得到
$$
</center>
$$\boldsymbol{a}=\boldsymbol{R_{\boldsymbol{yy}}^{-1}\boldsymbol{R_{\boldsymbol{y}\theta}}$$。
<center>
$$
\begin{aligned}
\hat{\theta} & =\boldsymbol{a}^{\mathrm{T}} \boldsymbol{y}+a[N] \\
& =\boldsymbol{R}_{\boldsymbol{y} \theta}{ }^{\mathrm{T}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}{ }^{-\mathbf{1}} \boldsymbol{y}+\mathrm{E}[\theta]-\boldsymbol{R}_{\boldsymbol{y} \theta}{ }^{\mathrm{T}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}{ }^{-\mathbf{1}} \mathrm{E}[\boldsymbol{y}] \\
& =\mathrm{E}[\theta]+\boldsymbol{R}_{\theta \boldsymbol{y}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}{ }^{-\mathbf{1}}(\boldsymbol{y}-\mathrm{E}[\boldsymbol{y}])
\end{aligned}
$$
</center>
这样就得到标量参数的LMMSE，并且其最小贝叶斯MSE为
<center>
$$
\operatorname{mse}(\hat{\theta})=R_{\theta \theta}-\boldsymbol{R}_{\theta \boldsymbol{y}} \boldsymbol{R}_{\boldsymbol{y} \boldsymbol{y}}{ }^{-\mathbf{1}} \boldsymbol{R}_{\boldsymbol{y} \theta}
$$
</center>
