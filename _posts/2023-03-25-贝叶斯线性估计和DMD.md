---
layout: post
title:  "贝叶斯线性估计和DMD"
author: "Geoffrey Hou"
comments: true
tags: NR
excerpt_separator: <!--more-->
sticky: true
hidden: true
---

<head>
    <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
            inlineMath: [['$','$']]
            }
        });
    </script>
</head>

最近在学习统计信号处理的估计理论部分，贝叶斯估计理论在DMD中的应用有些需要记录。<!--more-->

MMSE的一般表达式如下：
<center>$\widehat{\boldsymbol{\theta}}=\mathrm{E}[\boldsymbol{\theta}|\boldsymbol{y}]=\int\boldsymbol{\theta}p(\boldsymbol{\theta}|\boldsymbol{y})\mathrm{d}\boldsymbol{\theta}, p(\boldsymbol{\theta}|\boldsymbol{y})=\frac{p(\boldsymbol{y}|\boldsymbol{\theta})p(\boldsymbol{\theta})}{\int p(\boldsymbol{y}|\boldsymbol{\theta}) p(\boldsymbol{\theta})\mathrm{d}\boldsymbol{\theta}}$</center>
需要求多重积分，如果不做任何假设，很难求出闭合表达式。有两种假设可以考虑：联合高斯和线性估计量。

## 联合高斯假设下的线性贝叶斯估计量
### 多维高斯条件PDF
如果$\boldsymbol{x_{k \times 1}}$和$\boldsymbol{y_{l \times 1}}$是联合高斯的，均值矢量是$\left[E[\boldsymbol{x}]^{\mathrm{T}} \quad E[\boldsymbol{y}]^{\mathrm{T}}\right]^{\mathrm{T}}$，协方差是

$$
 \boldsymbol{R}=\left[
 \begin{matrix}
   \boldsymbol{R_{\boldsymbol{x} \boldsymbol{x}}} & \boldsymbol{R_{\boldsymbol{x} \boldsymbol{y}}} \\
   \boldsymbol{R_{\boldsymbol{y} \boldsymbol{x}}} & \boldsymbol{R_{\boldsymbol{y} \boldsymbol{y}}}
 \end{matrix}
 \right]
$$

那么条件PDF也是高斯的，并且

$$\mathrm{E}[\boldsymbol{y}|\boldsymbol{x}]=\mathrm{E}[\boldsymbol{y}]+\boldsymbol{R_{\boldsymbol{y}\boldsymbol{x}}}\boldsymbol{R_{\boldsymbol{x}\boldsymbol{x}}}^{-1}(\boldsymbol{x}-\mathrm{E}[\boldsymbol{x}])$$

$$\boldsymbol{R_{\boldsymbol{y}|\boldsymbol{x}}}=\boldsymbol{R_{\boldsymbol{y}\boldsymbol{y}}}-\boldsymbol{R_{\boldsymbol{y}\boldsymbol{x}}}\boldsymbol{R_{\boldsymbol{x}\boldsymbol{x}}}^{-1}\boldsymbol{R_{\boldsymbol{x}\boldsymbol{y}}}$$

### 贝叶斯一般线性模型
数据模型满足
<center>$\boldsymbol{y}=\boldsymbol{H\theta+n}$</center>
其中$\boldsymbol{y}$是$N \times 1$的观测数据矢量，$\boldsymbol{H}$是已知$N \times p$矩阵，$\boldsymbol{\theta}$是$p \times 1$的随机矢量，先验概率PDF满足均值为$\boldsymbol{\mu_{\theta}} $ ，方差为$\boldsymbol{C_{\theta}}$的高斯分布，$\boldsymbol{n}$是$N \times 1$的噪声矢量，PDF满足均值为$\boldsymbol{0}$，方差为$\boldsymbol{C_\theta}$的高斯分布，并且和$\boldsymbol{\theta}$无关。
在$\boldsymbol{y}$和$\boldsymbol{\theta}$联合高斯的条件下，后验PDF也是高斯的。

把$\boldsymbol{H\theta+n}$看作上小节中的$\boldsymbol{x}$，把$\boldsymbol{\theta}$看作上小节中的$\boldsymbol{y}$，有下面的推导：
<center>$$\mathrm{E}[\boldsymbol{x}]=\mathrm{E}[\boldsymbol{H} \boldsymbol{\theta}+\boldsymbol{n}]=\boldsymbol{H}\mathrm{E}[\boldsymbol{\theta}]=\boldsymbol{H}\boldsymbol{\mu}_\theta$$</center>
<center>$$\mathrm{E}[\boldsymbol{y}]=\mathrm{E}[\boldsymbol{\theta}]=\boldsymbol{\mu}_\theta$$</center>
<center>$$\begin{aligned} \boldsymbol{R}_{\boldsymbol{x} \boldsymbol{x}} & =\mathrm{E}\left[(\boldsymbol{x}-\mathrm{E}[\boldsymbol{x}])(\boldsymbol{x}-\mathrm{E}[\boldsymbol{x}])^{\mathrm{T}}\right] \\ & =\mathrm{E}\left[\left(\boldsymbol{H} \boldsymbol{\theta}+\boldsymbol{n}-\boldsymbol{H} \boldsymbol{\mu}_\theta\right)\left(\boldsymbol{H} \boldsymbol{\theta}+\boldsymbol{n}-\boldsymbol{H} \boldsymbol{\mu}_\theta\right)^{\mathrm{T}}\right] \\ & =\mathrm{E}\left[\left(\boldsymbol{H}\left(\boldsymbol{\theta}-\boldsymbol{\mu}_\theta\right)+\boldsymbol{n}\right)\left(\boldsymbol{H}\left(\boldsymbol{\theta}-\boldsymbol{\mu}_\theta\right)+\boldsymbol{n}\right)^{\mathrm{T}}\right] \\ & =\boldsymbol{H}\mathrm{E}\left[\left(\boldsymbol{\theta}-\boldsymbol{\mu}_\theta\right)\left(\boldsymbol{\theta}-\boldsymbol{\mu}_\theta\right)^{\mathrm{T}}\right] \boldsymbol{H}^{\mathrm{T}}+\mathrm{E}\left[\boldsymbol{n} \boldsymbol{n}^{\mathrm{T}}\right]\end{aligned}$$</center>
